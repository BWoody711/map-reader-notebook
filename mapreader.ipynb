{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical Character Recognition of Maps using the MapReader Library\n",
    "<p>By: Ben Woodward</p>\n",
    "<p>August 6th, 2024</p>\n",
    "<p>(Intro text to be added...)</p>\n",
    "<p>To learn more about the MapReader project, click <a href=''>here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required libraries\n",
    "Use PIP to create a virtual environment and install the libraries used in this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install dependencies\n",
    "#Install MapReader\n",
    "#Install detectron2\n",
    "#Install DeepSolo, DPText, and MapTextPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decrease Map Resolution\n",
    "To decrease compute time, this code takes your original map scan and reduces its resolution to 96 DPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify your preferred resolution, in DPI, here.\n",
    "resolution = 96\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Open the image file\n",
    "image_path = 'belden_map_bayfield.jpg'\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# Decrease resolution to your desired DPI level\n",
    "new_dpi = (resolution, resolution)\n",
    "\n",
    "# Save the image with new DPI\n",
    "output_path = image_path.split('.')[0] + resolution + 'dpi' + image_path.split('.')[1]\n",
    "img.save(output_path, dpi=new_dpi)\n",
    "\n",
    "print(f\"Image saved at {output_path} with DPI {new_dpi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Georeference your map\n",
    "Before proceeding to the next step, georeference your map in ArcGIS Pro or QGIS. This code is set up for georeferencing in EPSG: 4326."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load your map\n",
    "This code loads your map into the mapreader library for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1661b6df73164ab1b38c1a210099a523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Specify the path to your georeferenced map here\n",
    "georeferenced_map_filename = \"belden_map_bayfield_96dpi_georef_4326.tif\"\n",
    "\n",
    "from mapreader import loader\n",
    "my_files = loader(georeferenced_map_filename)\n",
    "my_files.add_geo_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the algorithm parameters\n",
    "Try changing these parameters to improve the accuracy of the algorithm's predictions for your map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 1024 #The documentation recommends using patches that are 1024x1024 pixels\n",
    "patch_overlap = 0.1 #Determine to what degree each patch overlaps with its neighbours. Experiment with different values to see what works best\n",
    "min_text_overlap = 0.7 #Determine the threshold for grouping nearby letters and words into one record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide your map into patches\n",
    "Many ML workflows involve dividing the image into patches/tiles to speed up computing times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving patches in directory named \"./patches_1024\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dbde5b76794a1ebf31e3bc7e2436ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belden_map_bayfield_96dpi_georef_4326.tif\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec796826fc4a48a88aa3ce7c79824d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_files.patchify_all(path_save=\"./patches_1024\", patch_size=patch_size, overlap=patch_overlap, rewrite=True)\n",
    "my_files.save_patches_as_geotiffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the DeepSolo ML Algorithm on your Map\n",
    "\n",
    "The DeepSolo algorithm can be used to detect text on your maps. This code block runs the algorithm. The algorithm can take several minutes to hours to run depending on the resolution and size of your map.\n",
    "\n",
    "If the algorithm is taking too long to run, you can try decreasing the resolution of your scanned map using the first code block. However, this may reduce the accuracy of the algorithm's output. That said, I have found that 96 DPI is sufficient in most cases.\n",
    "\n",
    "The MapReader library supports other algorithms, including DPText-DETR and MapTextPipeline. More information on those algorithms can be found <a href='https://mapreader.readthedocs.io/en/latest/using-mapreader/step-by-step-guide/6-spot-text.html'>here</a>.\n",
    "\n",
    "The parameters of the DeepSolo algorithm can be adjusted by modifying the \"finetune_150k_tt_mlt_13_15_textocr.yaml\" file. This is beyond the scope of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved parent dataframe as \"parent_df.csv\"\n",
      "[INFO] Saved patch dataframe as \"patch_df.csv\"\n",
      "[INFO] Reading \"./patch_df.csv\".\n",
      "[INFO] Reading \"./parent_df.csv\".\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e5435d82b3454f96839da107d55a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from mapreader.spot_text.deepsolo_runner import DeepSoloRunner\n",
    "from mapreader.spot_text.maptext_runner import MapTextRunner\n",
    "# from mapreader.spot_text.dptext_detr_runner import DPTextDETRRunner\n",
    "\n",
    "parent_df, patch_df = my_files.convert_images(save=True)\n",
    "\n",
    "#This one is the best balance between predictive power and performance. It can be run on a typical laptop.\n",
    "# deepsolo_runner = DeepSoloRunner(\n",
    "#     patch_df,\n",
    "#     parent_df,\n",
    "#     cfg_file = \"./DeepSolo/configs/R_50/IC15/finetune_150k_tt_mlt_13_15_textocr.yaml\",\n",
    "#     weights_file = \"./weights/ic15_res50_finetune_synth-tt-mlt-13-15-textocr.pth\"\n",
    "# )\n",
    "\n",
    "#This one shows you where it thinks the text is on the map, but does not digitize the text. It can be run on a typical laptop.\n",
    "# dptext_runner = DPTextDETRRunner(\n",
    "#     patch_df,\n",
    "#     parent_df,\n",
    "#     cfg_file = \"DPText-DETR/configs/DPText_DETR/ArT/R_50_poly.yaml\",\n",
    "#     weights_file = \"./weights/art_final.pth\",\n",
    "# )\n",
    "\n",
    "#This one likely has the best predictive power, but is very computationally intensive.\n",
    "maptext_runner = MapTextRunner(\n",
    "    \"./patch_df.csv\",\n",
    "    \"./parent_df.csv\",\n",
    "    cfg_file = \"MapTextPipeline/configs/ViTAEv2_S/rumsey/final_rumsey.yaml\",\n",
    "    weights_file = \"./weights/rumsey-finetune.pth\"\n",
    ")\n",
    "\n",
    "my_runner = maptext_runner\n",
    "\n",
    "patch_preds_df = my_runner.run_all(return_dataframe=True, min_ioa=min_text_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the output as a GeoJSON\n",
    "Save the text predictions as a GeoJSON file that can be visualized in GIS software. The MapReader library saves the predictions as polygons deliniating the extent of the text it read with its prediction for the text as an attribute (\"text\"). There is another attribute (\"score\") that denotes how confident the algorithm is in its prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_preds_df = my_runner.convert_to_parent_pixel_bounds(return_dataframe=True, deduplicate=True, min_ioa=min_text_overlap)\n",
    "geo_preds_df = my_runner.convert_to_coords(return_dataframe=True)\n",
    "my_runner.save_to_geojson(\"text_preds_dptext.geojson\")\n",
    "# geo_preds_df.to_csv(\"geo_preds.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapreader-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
